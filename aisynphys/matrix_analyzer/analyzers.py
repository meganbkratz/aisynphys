# -*- coding: utf-8 -*-

"""
Prototype code for analyzing connectivity and synaptic properties between cell classes.


"""
from __future__ import print_function, division

from collections import OrderedDict
import numpy as np
import pyqtgraph as pg
import pandas as pd
from statsmodels.stats.proportion import proportion_confint
from aisynphys.database import default_db as db
# from first_pulse_deconvolved_amps import get_deconvolved_first_pulse_amps
from neuroanalysis.data import TSeries, TSeriesList
from neuroanalysis.baseline import float_mode
from neuroanalysis.filter import bessel_filter
from aisynphys.connectivity import pair_was_probed, connection_probability_ci


thermal_colormap = pg.ColorMap(
                    [0, 0.1613, 0.3491, 1],
                    [(255, 255, 0, 255), (0, 206, 151, 255), (0, 119, 178, 255), (99, 0, 148, 255)],
            )

syn_typ_holding = {'ex': [-70], 'in': [-55]}

class FormattableNumber(float):

    @property
    def si_format(self):
        return pg.siFormat(self)
       
    # all of the below formats assume that the number is entered with no scaling and in the form (scale)(unit)
    @property
    def mV(self):
        if np.isnan(self):
            formatted_value = ''
        else:
            value = self*1e3
            formatted_value = ("%0.2f mV" % value)
        return formatted_value

    @property
    def uV(self):
        if np.isnan(self):
            formatted_value = ''
        else:
            value = self*1e6
            formatted_value = (u"%0.f μV" % value)
        return formatted_value

    @property
    def pA(self):
        if np.isnan(self):
            formatted_value = ''
        else:
            value = self*1e12
            formatted_value = ("%0.2f pA" % value)
        return formatted_value

    @property
    def ms(self):
        if np.isnan(self):
            formatted_value = ''
        else:
            value = self*1e3
            formatted_value = ("%0.2f ms" % value)
        return formatted_value

    @property
    def us(self):
        if np.isnan(self):
            formatted_value = ''
        else:
            value = self*1e6
            formatted_value = ("%0.2f μs" % value)
        return formatted_value

    @property
    def mm(self):
        if np.isnan(self):
            formatted_value = ''
        else:
            value = self*1e3
            formatted_value = ("%0.2f mm" % value)
        return formatted_value

    @property
    def um(self):
        if np.isnan(self):
            formatted_value = ''
        else:
            value = self*1e6
            formatted_value = ("%d μm" % value)
        return formatted_value

class Analyzer(pg.QtCore.QObject):

    sigOutputChanged = pg.QtCore.Signal(object)

    def group_result(self, pair_groups):
        if self.group_results is not None:
            return self.group_results

        ## create a MultiIndex so that group_results will have the same structure as when it was generated by results.groupby
        pre_types = set()
        post_types = set()
        for pair_class in pair_groups.keys():
            pre, post = pair_class
            pre_types.add(pre)
            post_types.add(post)
        index = pd.MultiIndex.from_product([pre_types, post_types], names=['pre_class', 'post_class'])

        group_results = None
        for pair_class, pair_group in pair_groups.items():
            if len(pair_group) == 0:
                continue
            res = self.results.loc[pair_group]
            res['extra'] = [0]*len(res.index) ## create an extra column to group by.
            result = res.groupby(['extra']).agg(self.summary_stat) 

            if group_results is None:
                group_results = pd.DataFrame(result, index=index)
                #dtype_dict = {}
                #for i in range(len(result.columns)):
                #    dtype_dict[result.columns[i]] = result.dtypes[result.columns[i]]

            pre_class, post_class = pair_class
            group_results.loc[pre_class, post_class] = result.iloc[0]

        ### filter out all the pair_groups we don't have data for. (To be consistent with results from .groupby)
        nan_indices = group_results.loc[group_results.isnull().all(axis=1), :].index.tolist()
        for i in nan_indices:
            group_results = group_results.drop(i)

        group_results = group_results.astype(self.summary_dtypes)

        self.group_results = group_results
        return self.group_results




class ConnectivityAnalyzer(Analyzer):

    def __init__(self, analyzer_mode):
        Analyzer.__init__(self)
        self.name = 'connectivity'
        self.results = None
        self.group_results = None
        self.pair_items = {}
        self.analyzer_mode = analyzer_mode
        #self._signalHandler = ConnectivityAnalyzer.SignalHandler()
        #self.sigOutputChanged = self._signalHandler.sigOutputChanged

        self.fields = [
            ('Probed Connection', {}),
            ('Connected', {}),
            ('Gap Junction', {}),
            ('Distance', {'mode': 'range', 'units': 'm', 'defaults': {
                'Min': 0e-6,
                'Max': 300e-6,
                'colormap': pg.ColorMap(
                    [0, 0.25, 0.5, 0.75, 1.0],
                    [(255,255,100,255), (255,100,0,255), (0,0,100,255), (140,0,0,255), (80,0,80,255)],
            )}}),
            ('Connection Probability', {'mode': 'range', 'defaults': {
                'Operation': 'Add', 
                'colormap': pg.ColorMap(
                [0, 0.01, 0.03, 0.1, 0.3, 1.0],
                [(0,0,100, 255), (80,0,80, 255), (140,0,0, 255), (255,100,0, 255), (255,255,100, 255), (255,255,255, 255)],
            )}}),
            ('Gap Junction Probability', {'mode': 'range', 'defaults': {
                'colormap': pg.ColorMap(
                   [0, 0.01, 0.03, 0.1, 0.3, 1.0],
                    [(0,0,100, 255), (80,0,80, 255), (140,0,0, 255), (255,100,0, 255), (255,255,100, 255), (255,255,255, 255)],
            )}}),
            ('None', {}),
            ]

        self.summary_stat = {
            'conn_no_data': self.metric_summary,
            'Probed Connection': self.metric_summary,
            'Connected': self.metric_summary,
            'Gap Junction': [self.metric_summary, self.metric_conf],
            'Connection Probability': [self.metric_summary, self.metric_conf],
            'Gap Junction Probability': [self.metric_summary, self.metric_conf],
            'Distance': [self.metric_summary, self.metric_conf],
        }

        if self.analyzer_mode == 'internal':
            self.fields.append(
                ('matrix_completeness', {'mode': 'range', 'defaults': {
                'colormap': pg.ColorMap(
                    [0, 0.25, 0.5, 0.75, 1.0],
                    [(0,0,100,255), (80,0,80,255), (140,0,0,255), (255,100,0,255), (255,255,100,255)],
            )}}))

            self.summary_stat['matrix_completeness'] = [self.metric_summary, self.metric_conf]

        self.summary_dtypes = {
            ('conn_no_data', 'metric_summary'): bool,
            ('Probed Connection', 'metric_summary'): int,
            ('Connected', 'metric_summary'): int,
            ('Gap Junction', 'metric_summary'):int,
        }

        self.text = {
            'Probed Connection': '{Probed Connection}',
            'Connected': '{Connected}',
            'Gap Junction': '{Gap Junction}',
            'Connection Probability': '{Connected}/{Probed Connection}',
            'Gap Junction Probability': '{Gap Junction}/{Probed Connection}',
            'matrix_completeness': '{Connected}/{Probed Connection}',
            'Distance': '{Distance.um}',
        }

    def metric_summary(self, x): 
        if x.name == 'conn_no_data':
            return all(x)
        if x.name == 'Distance':
            return np.nanmean(x)
        if x.name in ['Connected', 'Probed Connection', 'Gap Junction']:
            #print("+++ metric_summary: ", x.name)
            #print(x)
            #print(type(x))
            return sum(filter(None, x))
        else:
            p = x.apply(pd.Series)
            p1 = p.sum()
            connected = float(p1[0])
            probed = float(p1[1])

            if x.name == 'matrix_completeness':
                probed_progress = probed/80
                connected_progress = connected/6
                return np.clip(np.where(probed_progress > connected_progress, probed_progress, connected_progress), 0, 1)
            elif x.name.endswith('Probability'):
                if probed == 0.:
                    return float('nan')
                else:
                    return connected/probed       

    def metric_conf(self, x):
        if x.name.endswith('Probability'):
            p = x.apply(pd.Series)
            p1 = p.sum()
            connected = float(p1[0])
            probed = float(p1[1])
            return connection_probability_ci(connected, probed)
        if x.name == 'Distance':
            return [-np.nanstd(x), np.nanstd(x)]
        else:
            return float('nan')
    
    def invalidate_output(self):
        self.results = None
        self.group_results = None

    def measure(self, pair_groups):
        """Given a list of cell pairs and a dict that groups cells together by class,
        return a structure that describes connectivity of each cell pair.
        """    
        if self.results is not None:
            return self.results

        results = OrderedDict()

        for key, class_pairs in pair_groups.items():
            pre_class, post_class = key
            for pair in class_pairs:
                no_data = False
                probed = pair_was_probed(pair, pre_class.output_synapse_type)
                if probed is False:
                    no_data = True

                connected = pair.has_synapse if probed is True else False
                gap = pair.has_electrical if probed is True else False
                distance = pair.distance if probed is True else float('nan')
                

                results[pair] = {
                'conn_no_data': no_data,
                'pre_class': pre_class,
                'post_class': post_class,
                'Probed Connection': probed,
                'Connected': connected,
                'Gap Junction': gap,
                'Distance': distance,
                'Connection Probability': [int(connected) if connected is not None else 0, int(probed) if probed is not None else 0],
                'Gap Junction Probability': [int(gap) if gap is not None else 0, int(probed) if probed is not None else 0],
                'matrix_completeness': [int(connected) if connected is not None else 0, int(probed) if probed is not None else 0],
                
                }

                if self.analyzer_mode == 'external':
                    del(results[pair]['matrix_completeness'])

        self.results = pd.DataFrame.from_dict(results, orient='index')

        return self.results

    def output_fields(self):

        return self.fields

    def print_element_info(self, pre_class, post_class, element, field_name):
        connections = element[element['Connected'] == True].index.tolist()
        print ("Connection type: %s -> %s" % (pre_class, post_class))
        print ("Connected Pairs:")
        for connection in connections:
            print ("\t %s" % (connection))
        gap_junctions = element[element['Gap Junction'] == True].index.tolist()
        print ("Gap Junctions:")
        for gap in gap_junctions:
            print ("\t %s" % (gap))
        probed_pairs = element[element['Probed Connection'] == True].index.tolist()
        print ("Probed Pairs:")
        for probed in probed_pairs:
            print ("\t %s" % (probed))
        
        
    def plot_element_data(self, pre_class, post_class, element, field_name, color='g', trace_plt=None):
        summary = element.agg(self.summary_stat)  
        val = summary[field_name]['metric_summary']
        line = pg.InfiniteLine(val, pen={'color': color, 'width': 2}, movable=False)
        scatter = None
        tracesA = []
        tracesB = []
        connections = element[element['Connected'] == True].index.tolist()
        for pair in connections:
            # rsf = pair.resting_state_fit
            synapse = pair.synapse
            if synapse is None:
                continue
            arfs = pair.avg_response_fits
            latency = pair.synapse.latency
            syn_typ = pair.synapse.synapse_type
            self.pair_items[pair.id] = []
            trace_itemA = None
            trace_itemB = None
            # if rsf is not None:
            #     traceA = TSeries(data=rsf.ic_avg_data, sample_rate=db.default_sample_rate)
            #     start_time = rsf.ic_avg_data_start_time
            #     if latency is not None and start_time is not None:
            #         xoffset = start_time - latency
            #         baseline_window = [abs(xoffset)-1e-3, abs(xoffset)]
            #         traceA = format_trace(traceA, baseline_window, x_offset=xoffset, align='psp')
            #         trace_itemA = trace_plt[0].plot(traceA.time_values, traceA.data)
            #         trace_itemA.pair = pair
            #         trace_itemA.curve.setClickable(True)
            #         trace_itemA.sigClicked.connect(self.trace_plot_clicked)
            #         self.pair_items[pair.id].append(trace_itemA)
            #         tracesA.append(traceA)
            if arfs is not None:
                for arf in arfs:
                    if arf.holding in syn_typ_holding[syn_typ] and arf.manual_qc_pass is True and latency is not None:
                        if arf.clamp_mode == 'vc' and trace_itemA is None:
                            traceA = TSeries(data=arf.avg_data, sample_rate=db.default_sample_rate)
                            traceA = bessel_filter(traceA, 5000, btype='low', bidir=True)
                            start_time = arf.avg_data_start_time
                            if start_time is not None:
                                xoffset = start_time - latency
                                baseline_window = [abs(xoffset)-1e-3, abs(xoffset)]
                                traceA = format_trace(traceA, baseline_window, x_offset=xoffset, align='psp')
                                trace_itemA = trace_plt[0].plot(traceA.time_values, traceA.data)
                                trace_itemA.pair = pair
                                trace_itemA.curve.setClickable(True)
                                trace_itemA.sigClicked.connect(self.trace_plot_clicked)
                                self.pair_items[pair.id].append(trace_itemA)
                                tracesA.append(traceA)
                        if arf.clamp_mode == 'ic' and trace_itemB is None:
                            traceB = TSeries(data=arf.avg_data, sample_rate=db.default_sample_rate)
                            start_time = arf.avg_data_start_time
                            if latency is not None and start_time is not None:
                                xoffset = start_time - latency
                                baseline_window = [abs(xoffset)-1e-3, abs(xoffset)]
                                traceB = format_trace(traceB, baseline_window, x_offset=xoffset, align='psp')
                                trace_itemB = trace_plt[1].plot(traceB.time_values, traceB.data)
                                trace_itemB.pair = pair
                                trace_itemB.curve.setClickable(True)
                                trace_itemB.sigClicked.connect(self.trace_plot_clicked)
                                tracesB.append(traceB)
            self.pair_items[pair.id] = [trace_itemA, trace_itemB]

        if len(tracesA) > 0:
            grand_trace = TSeriesList(tracesA).mean()
            name = ('%s->%s' % (pre_class, post_class))
            # trace_plt[0].addLegend()
            trace_plt[0].plot(grand_trace.time_values, grand_trace.data, pen={'color': color, 'width': 3}, name=name)
            trace_plt[0].setXRange(-5e-3, 20e-3)
            trace_plt[0].setLabels(left=('', 'A'), bottom=('Response Onset', 's'))
            trace_plt[0].setTitle('Voltage Clamp')
        if len(tracesB) > 0:
            grand_trace = TSeriesList(tracesB).mean()
            trace_plt[1].plot(grand_trace.time_values, grand_trace.data, pen={'color': color, 'width': 3})
            trace_plt[1].setLabels(right=('', 'V'), bottom=('Response Onset', 's'))
            trace_plt[1].setTitle('Current Clamp')
        return line, scatter

    def summary(self, ):
        total_connected = self.results['Connected'].sum()
        total_probed = self.results['Probed Connection'].sum()
        print ("Total connected / probed\t %d / %d" % (total_connected, total_probed))

        # if metric == 'matrix_completeness':
        #     total_progress = 0
        #     for connectivity in results.values():
        #         total_progress += connectivity['matrix_completeness']
        #     n_elements = len([element for element in results.values() if element['no_data'] is False])

        #     print ("Total progress\t %0.1f%%, %d elements" % (100*total_progress/n_elements, n_elements))

    def scatter_plot_clicked(self, scatterplt, points):
        pair = points[0].data()
        self.select_pair(pair)

    def trace_plot_clicked(self, trace):
        pair = trace.pair
        self.deselect_pairs()
        self.select_pair(pair)

    def select_pair(self, pair):
        traceA, traceB = self.pair_items[pair.id]
        if traceA is not None:
            traceA.setPen('y', width=3)
            traceA.setZValue(10) 
        if traceB is not None:
            traceB.setPen('y', width=3)
            traceB.setZValue(10) 
        print('Clicked:' '%s' % pair)
        print(self.results.loc[pair])

    def deselect_pairs(self):
        for (traceA, traceB) in self.pair_items.values():
            if traceA is not None:
                traceA.setPen('w', width=1)
                traceA.setZValue(-10)
            if traceB is not None:
                traceB.setPen('w', width=1)
                traceB.setZValue(-10)



class StrengthAnalyzer(Analyzer):

    def __init__(self):
        Analyzer.__init__(self)
        self.name = 'strength'
        self.results = None
        self.group_results = None
        self.pair_items = {}
        #self._signalHandler = ConnectivityAnalyzer.SignalHandler()
        #self.sigOutputChanged = self._signalHandler.sigOutputChanged

        self.summary_stat = {
        'PSP Amplitude': [self.metric_summary, self.metric_conf],
        'Latency': [self.metric_summary, self.metric_conf],
        'PSP Rise Time': [self.metric_summary, self.metric_conf],
        'PSP Decay Tau': [self.metric_summary, self.metric_conf],
        'PSC Amplitude': [self.metric_summary, self.metric_conf],
        'PSC Rise Time': [self.metric_summary, self.metric_conf],
        'PSC Decay Tau': [self.metric_summary, self.metric_conf],
        'strength_no_data': self.metric_summary,
        }
        self.summary_dtypes = {} ## dict to specify how we want to cast different summary measures
        ## looks like {('ic_fit_amp_all', 'metric_summary'):float}

        self.fields = [
            # all pulses
            ('PSP Amplitude', {'mode': 'range', 'units': 'V', 'defaults': {
                'Min': -1e-3, 
                'Max': 1e-3, 
                'colormap': pg.ColorMap(
                [0, 0.5, 1.0],
                [(0, 0, 255, 255), (56, 0, 87, 255), (255, 0, 0, 255)],
            )}}),
            ('PSC Amplitude', {'mode': 'range', 'units': 'A', 'defaults': {
                'Min': -20e-12, 
                'Max': 20e-12, 
                'colormap': pg.ColorMap(
                [0, 0.5, 1.0],
                [(255, 0, 0, 255), (56, 0, 87, 255), (0, 0, 255, 255)],
            )}}),
            ('PSP Rise Time', {'mode': 'range', 'units': 's', 'defaults': {
                'Min': 1e-3, 
                'Max': 10e-3,
                'colormap': thermal_colormap,
            }}),
            ('PSC Rise Time', {'mode': 'range', 'units': 's', 'defaults': {
                'Min': 0.5e-3, 
                'Max': 5e-3,
                'colormap': thermal_colormap,
            }}),
            ('PSP Decay Tau', {'mode': 'range', 'units': 's', 'defaults': {
                'Max': 500e-3,
                'colormap': thermal_colormap,
            }}),
            ('PSC Decay Tau', {'mode': 'range', 'units': 's', 'defaults': {
                'Max': 20e-3,
                'colormap': thermal_colormap,
            }}),
            ('Latency', {'mode': 'range', 'units': 's', 'defaults': {
                'Min': 0.5e-3, 
                'Max': 4e-3,
                'colormap': thermal_colormap,
            }}),
            ('None',{}),
        ]

        self.text = {
            'PSP Amplitude': '{PSP Amplitude.mV}',
            'PSC Amplitude': '{PSC Amplitude.pA}',
            'Latency': '{Latency.ms}',
            'PSP Rise Time': '{PSP Rise Time.ms}',
            'PSP Decay Tau': '{PSP Decay Tau.ms}',
            'PSC Rise Time': '{PSC Rise Time.ms}',
            'PSC Decay Tau': '{PSC Decay Tau.ms}',
        }

    def invalidate_output(self):
        self.results = None
        self.group_results = None
        self.pair_items = {}

    def measure(self, pair_groups):
        """Given a list of cell pairs and a dict that groups cells together by class,
        return a structure that describes strength and kinetics of each cell pair.
        """  
        if self.results is not None:
            return self.results

        results = OrderedDict()
        
        for key, class_pairs in pair_groups.items():
            pre_class, post_class = key

            for pair in class_pairs:
                if pair.has_synapse is not True:
                    no_data = True
                elif pair.has_synapse is True:
                    no_data = False
                    synapse = pair.synapse
                    if synapse is None:
                        no_data = True
                    else:
                        psp_amp = synapse.psp_amplitude
                        psp_decay_tau = synapse.psp_decay_tau
                        psp_rise_time = synapse.psp_rise_time 
                        psc_amp = synapse.psc_amplitude
                        psc_rise_time = synapse.psc_rise_time
                        psc_decay_tau = synapse.psc_decay_tau
                        latency = synapse.latency

                    

                results[pair] = {
                'strength_no_data': no_data,
                'pre_class': pre_class,
                'post_class': post_class,
                'PSP Amplitude': psp_amp if no_data is False else float('nan'),
                'PSP Rise Time': psp_rise_time if no_data is False else float('nan'),
                'PSP Decay Tau': psp_decay_tau if no_data is False else float('nan'),
                'PSC Amplitude': psc_amp if no_data is False else float('nan'),
                'PSC Rise Time': psc_rise_time if no_data is False else float('nan'),
                'PSC Decay Tau': psc_decay_tau if no_data is False else float('nan'),
                'Latency': latency if no_data is False else float('nan'),
                }

        self.results = pd.DataFrame.from_dict(results, orient='index')

        return self.results

    def output_fields(self):

        return self.fields

    def metric_summary(self, x):
        if x.name == 'strength_no_data':
            return all(x)
        else:
            return x.mean()

    def metric_conf(self, x):
        return [-x.std(), x.std()]

    def print_element_info(self, pre_class, post_class, element, field_name=None):
        if field_name is not None:
            units = [field[1].get('units', '') for field in self.fields if field[0] == field_name][0] 
            print ("Connection type: %s -> %s" % (pre_class, post_class))    
            print ("\t Grand Average %s = %s" % (field_name, pg.siFormat(element[field_name].mean(), suffix=units)))
            print ("Connected Pairs:")
            no_qc_data = []
            for pair, value in element[field_name].iteritems():
                if pair.has_synapse is not True:
                    continue
                if np.isnan(value):
                    no_qc_data.append(pair)
                else:
                    print ("\t %s" % (pair))
                    print ("\t\t Average %s: %s" % (field_name, pg.siFormat(value, suffix=units)))
            print("\t No QC Data:")
            for pair in no_qc_data:
                print ("\t\t %s" % (pair))

    def plot_element_data(self, pre_class, post_class, element, field_name, color='g', trace_plt=None):
        val = element[field_name].mean()
        line = pg.InfiniteLine(val, pen={'color': color, 'width': 2}, movable=False)
        scatter = None
        baseline_window = int(db.default_sample_rate * 5e-3)
        values = []
        tracesA = []
        tracesB = []
        point_data = []
        for pair, value in element[field_name].iteritems():
            latency = self.results.loc[pair]['Latency']
            trace_itemA = None
            trace_itemB = None
            if pair.has_synapse is not True:
                continue
            if np.isnan(value):
                continue
            syn_typ = pair.synapse.synapse_type
            rsf = pair.resting_state_fit
            if rsf is not None:
                nrmse = rsf.vc_nrmse if field_name.startswith('PSC') else rsf.ic_nrmse
                # if nrmse is None or nrmse > 0.8:
                #     continue
                data = rsf.vc_avg_data if field_name.startswith('PSC') else rsf.ic_avg_data
                traceA = TSeries(data=data, sample_rate=db.default_sample_rate)
                if field_name.startswith('PSC'):
                    traceA = bessel_filter(traceA, 5000, btype='low', bidir=True)
                bessel_filter(traceA, 5000, btype='low', bidir=True)
                start_time = rsf.vc_avg_data_start_time if field_name.startswith('PSC') else rsf.ic_avg_data_start_time
                if latency is not None and start_time is not None:
                    if field_name == 'Latency':
                        xoffset = start_time + latency
                    else:
                        xoffset = start_time - latency
                    baseline_window = [abs(xoffset)-1e-3, abs(xoffset)]
                    traceA = format_trace(traceA, baseline_window, x_offset=xoffset, align='psp')
                    trace_itemA = trace_plt[1].plot(traceA.time_values, traceA.data)
                    trace_itemA.pair = pair
                    trace_itemA.curve.setClickable(True)
                    trace_itemA.sigClicked.connect(self.trace_plot_clicked)
                    tracesA.append(traceA)
                if field_name == 'Latency' and rsf.vc_nrmse is not None: #and rsf.vc_nrmse < 0.8:
                    traceB = TSeries(data=rsf.vc_avg_data, sample_rate=db.default_sample_rate)
                    traceB = bessel_filter(traceB, 5000, btype='low', bidir=True)
                    start_time = rsf.vc_avg_data_start_time
                    if latency is not None and start_time is not None:
                        xoffset = start_time + latency
                        baseline_window = [abs(xoffset)-1e-3, abs(xoffset)]
                        traceB = format_trace(traceB, baseline_window, x_offset=xoffset, align='psp')
                        trace_itemB = trace_plt[0].plot(traceB.time_values, traceB.data)
                        trace_itemB.pair = pair
                        trace_itemB.curve.setClickable(True)
                        trace_itemB.sigClicked.connect(self.trace_plot_clicked)
                        tracesB.append(traceB)
            self.pair_items[pair.id] = [trace_itemA, trace_itemB]
            if trace_itemA is not None:
                values.append(value)
                point_data.append(pair)
        y_values = pg.pseudoScatter(np.asarray(values, dtype=float), spacing=1)
        scatter = pg.ScatterPlotItem(symbol='o', brush=(color + (150,)), pen='w', size=12)
        scatter.setData(values, y_values + 10., data=point_data)
        for point in scatter.points():
            pair_id = point.data().id
            self.pair_items[pair_id].extend([point, color])
        scatter.sigClicked.connect(self.scatter_plot_clicked)
        if len(tracesA) > 0:
            if field_name == 'Latency':     
                spike_line = pg.InfiniteLine(0, pen={'color': 'w', 'width': 1, 'style': pg.QtCore.Qt.DotLine}, movable=False)
                trace_plt[0].addItem(spike_line)
                x_label = 'Time from presynaptic spike'
            else:
                x_label = 'Response Onset'
            grand_trace = TSeriesList(tracesA).mean()
            name = ('%s->%s, n=%d' % (pre_class, post_class, len(tracesA)))
            trace_plt[1].plot(grand_trace.time_values, grand_trace.data, pen={'color': color, 'width': 3}, name=name)
            units = 'A' if field_name.startswith('PSC') else 'V'
            title = 'Voltage Clamp' if field_name.startswith('PSC') else 'Current Clamp'
            trace_plt[1].setXRange(-5e-3, 20e-3)
            trace_plt[1].setLabels(left=('', units), bottom=(x_label, 's'))
            trace_plt[1].setTitle(title)
        if len(tracesB) > 0:
            trace_plt[1].setLabels(right=('', units))
            trace_plt[1].hideAxis('left')
            spike_line = pg.InfiniteLine(0, pen={'color': 'w', 'width': 1, 'style': pg.QtCore.Qt.DotLine}, movable=False)
            trace_plt[0].addItem(spike_line)
            grand_trace = TSeriesList(tracesB).mean()
            trace_plt[0].plot(grand_trace.time_values, grand_trace.data, pen={'color': color, 'width': 3})
            trace_plt[0].setXRange(-5e-3, 20e-3)
            trace_plt[0].setLabels(left=('', 'A'), bottom=('Time from presynaptic spike', 's'))
            trace_plt[0].setTitle('Voltage Clamp')
        return line, scatter

    def scatter_plot_clicked(self, scatterplt, points):
        pair = points[0].data()
        self.deselect_pairs()
        self.select_pair(pair)

    def trace_plot_clicked(self, trace):
        pair = trace.pair
        self.deselect_pairs()
        self.select_pair(pair)

    def select_pair(self, pair):
        traceA, traceB, point, _ = self.pair_items[pair.id]
        point.setBrush(pg.mkBrush('y'))
        point.setSize(15)
        if traceA is not None:
            traceA.setPen('y', width=3)
            traceA.setZValue(10)
        if traceB is not None:
            traceB.setPen('y', width=3)
            traceB.setZValue(10)
        print('Clicked:' '%s' % pair)
        print(self.results.loc[pair])

    def deselect_pairs(self):
        for (traceA, traceB, point, color) in self.pair_items.values():
            point.setBrush(color + (150,))
            point.setSize(12)
            if traceA is not None:
                traceA.setPen('w', width=1)
                traceA.setZValue(-10)
            if traceB is not None:
                traceB.setPen('w', width=1)
                traceB.setZValue(-10)

    def summary(self, results, metric):
        print('')

class DynamicsAnalyzer(Analyzer):
    def __init__(self):
        Analyzer.__init__(self)
        self.name = 'dynamics'
        self.results = None
        self.group_results = None
        self.pair_items = {}
        #self._signalHandler = ConnectivityAnalyzer.SignalHandler()
        #self.sigOutputChanged = self._signalHandler.sigOutputChanged

        self.summary_stat = {
            'dynamics_no_data': self.metric_summary,
            'Paired pulse STP': [self.metric_summary, self.metric_conf],
            'Train-induced STP': [self.metric_summary, self.metric_conf],
            'STP recovery': [self.metric_summary, self.metric_conf],
        }
        self.summary_dtypes = {} ## dict to specify how we want to cast different summary measures
        ## looks like {('pulse_ratio_8_1_50hz', 'metric_summary'):float}
        
        self.fields = [
            ('Paired pulse STP', {'mode': 'range', 'defaults': {
                'Min': -1, 
                'Max': 1, 
                'colormap': pg.ColorMap(
                [0, 0.5, 1.0],
                [(0, 0, 255, 255), (56, 0, 87, 255), (255, 0, 0, 255)],
            )}}),
            ('Train-induced STP', {'mode': 'range', 'defaults': {
                'Min': -1, 
                'Max': 1, 
                'colormap': pg.ColorMap(
                [0, 0.5, 1.0],
                [(0, 0, 255, 255), (56, 0, 87, 255), (255, 0, 0, 255)],
            )}}),
            ('STP recovery', {'mode': 'range', 'defaults': {
                'Min': -1, 
                'Max': 1, 
                'colormap': pg.ColorMap(
                [0, 0.5, 1.0],
                [(0, 0, 255, 255), (56, 0, 87, 255), (255, 0, 0, 255)],
            )}}),
            ('None', {}),
        ]
        
        self.text = {
            'Paired pulse STP': '{Paired pulse STP:0.2f}',
            'Train-induced STP': '{Train-induced STP:0.2f}',
            'STP recovery': '{STP recovery:0.2f}',
        }

    def invalidate_output(self):
        self.results = None
        self.group_results = None

    def metric_summary(self, x):
        if x.name == 'dynamics_no_data':
            return all(x)
        else:
            return np.nanmean(x)

    def metric_conf(self, x):
        return [-np.nanstd(x), np.nanstd(x)]

    def measure(self, pair_groups):
        """Given a list of cell pairs and a dict that groups cells together by class,
        return a structure that describes dynamics of each cell pair.
        """  
        if self.results is not None:
            return self.results

        results = OrderedDict()
        for key, class_pairs in pair_groups.items():
            pre_class, post_class = key
            
            for pair in class_pairs:
                if pair.has_synapse is not True:
                    no_data = True
                    dynamics = None
                elif pair.has_synapse is True:
                    no_data = False
                    dynamics = pair.dynamics

                results[pair] = {
                'dynamics_no_data': no_data,
                'pre_class': pre_class,
                'post_class': post_class,
                'Paired pulse STP': dynamics.stp_initial_50hz if dynamics is not None else float('nan'),
                'Train-induced STP': dynamics.stp_induction_50hz if dynamics is not None else float('nan'),
                'STP recovery': dynamics.stp_recovery_250ms if dynamics is not None else float('nan'),
                }

        
        self.results = pd.DataFrame.from_dict(results, orient='index')
        
        return self.results

    # def group_result(self):
    #     if self.group_results is not None:
    #         return self.group_results

    #     self.group_results = self.results.groupby(['pre_class', 'post_class']).agg(self.summary_stat)
    #     return self.group_results

    def output_fields(self):
       
        return self.fields

    def print_element_info(self, pre_class, post_class, element, field_name=None):
        if field_name is not None:
            print ("Connection type: %s -> %s" % (pre_class, post_class))    
            print ("\t Grand Average %s = %s" % (field_name, element[field_name].mean()))
            print ("Connected Pairs:")
            no_qc_data = []
            for pair, value in element[field_name].iteritems():
                if pair.has_synapse is not True:
                    continue
                if np.isnan(value):
                    no_qc_data.append(pair)
                else:
                    print ("\t %s" % (pair))
                    print ("\t\t Average %s: %0.2f" % (field_name, value))
            print("\t No QC Data:")
            for pair in no_qc_data:
                print ("\t\t %s" % (pair))

    def plot_element_data(self, pre_class, post_class, element, field_name, color='g', trace_plt=None):
        trace_plt = None
        val = element[field_name].mean()
        line = pg.InfiniteLine(val, pen={'color': color, 'width': 2}, movable=False)
        scatter = None
        baseline_window = int(db.default_sample_rate * 5e-3)
        values = []
        traces = []
        point_data = []
        for pair, value in element[field_name].iteritems():
            if np.isnan(value):
                continue
            traces = []
            if trace_plt is not None:
                if rsf is not None:
                    trace = rsf.ic_avg_data
                    start_time = rsf.ic_avg_data_start_time
                    latency = pair.synapse.latency
                    if latency is not None and start_time is not None:
                        xoffset = start_time - latency
                        trace = format_trace(trace, baseline_window, x_offset=xoffset, align='psp')
                        trace_plt.plot(trace.time_values, trace.data)
                        traces.append(trace)
            values.append(value)
            point_data.append(pair)
            y_values = pg.pseudoScatter(np.asarray(values, dtype=float), spacing=1)
            scatter = pg.ScatterPlotItem(symbol='o', brush=(color + (150,)), pen='w', size=12)
            scatter.setData(values, y_values + 10., data=point_data)
        for point in scatter.points():
            pair_id = point.data().id
            self.pair_items[pair_id] = [point, color]
        scatter.sigClicked.connect(self.scatter_plot_clicked)
        if len(traces) > 0:
            grand_trace = TSeriesList(traces).mean()
            trace_plt.plot(grand_trace.time_values, grand_trace.data, pen={'color': color, 'width': 3})
            units = 'V' if field_name.startswith('ic') else 'A'
            trace_plt.setXRange(0, 20e-3)
            trace_plt.setLabels(left=('', units), bottom=('Time from stimulus', 's'))
        return line, scatter

    def scatter_plot_clicked(self, scatterplt, points):
        pair = points[0].data()
        self.deselect_pairs()
        self.select_pair(pair)

    def trace_plot_clicked(self, trace):
        pair = trace.pair
        self.deselect_pairs()
        self.select_pair(pair)

    def select_pair(self, pair):
        point= self.pair_items[pair.id]
        point.setBrush(pg.mkBrush('y'))
        point.setSize(15)
        # if traceA is not None:
        #     traceA.setPen('y', width=3)
        #     traceA.setZValue(10)
        # if traceB is not None:
        #     traceB.setPen('y', width=3)
        #     traceB.setZValue(10)
        print('Clicked:' '%s' % pair)
        print(self.results.loc[pair])

    def summary(self, results, metric):
        print('')


def format_trace(trace, baseline_win, x_offset=1e-3, align='spike'):
    # align can be to the pre-synaptic spike (default) or the onset of the PSP ('psp')
    baseline = float_mode(trace.time_slice(baseline_win[0],baseline_win[1]).data)
    trace = TSeries(data=(trace.data-baseline), sample_rate=db.default_sample_rate)
    if align == 'psp':
        trace.t0 = x_offset
    return trace

def get_all_output_fields(analyzer_list):
    data_fields = []
    text_fields = {}
    # confidence_fields = []
    for analyzer in analyzer_list:
        data_fields.extend(analyzer.output_fields())
        text_fields.update(analyzer.text)
        # confidence_fields.extend(analyzer.output_fields()['show_confidence'])

    return data_fields, text_fields

def results_scatter(results, field_name, field, plt):
    vals = [result[field_name] for result in results.values() if np.isfinite(result[field_name])]
    y, x = np.histogram(vals, bins=np.linspace(min(vals), max(vals), 10))
    plt.plot(x, y, stepMode=True, fillLevel=0, brush=(255,255,255,150))
    units = field.get('units', '')
    plt.setLabels(left='Count', bottom=(field_name, units))
